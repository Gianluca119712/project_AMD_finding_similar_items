{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gianluca119712/project_AMD_finding_similar_items/blob/main/GianlucaMorena_project_AMD_finding_similar_items.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfYw2ncSjm0h"
      },
      "source": [
        "author: **Gianluca Morena (42508A)**\n",
        "\n",
        "course: *Algorithms for massive data, cloud and distributed computing*\n",
        "\n",
        "degree: *MSc Data science for economics*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOOYF7QNjp1m"
      },
      "source": [
        "# Project 1: **Finding similar items**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD-DMmFrjr5A"
      },
      "source": [
        " TASK: implement a detector of pairs of similar book review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azq0KDsOjxRA"
      },
      "source": [
        "## PySpark, Libraries, set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ovweMNs3yFlr"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark\n",
        "!pip install -q kaggle\n",
        "!pip install -q stop-words\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import re\n",
        "\n",
        "from pyspark.sql.functions import size\n",
        "from pyspark.sql.functions import col, sum\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "from stop_words import get_stop_words\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E8xc-lq6yGSu"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"finding_similar_items\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NIp6XIckFjH"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "noE3FCD8yGX2"
      },
      "outputs": [],
      "source": [
        "def sample_size(df, percent, output_name=\"dataset\", seed=42):\n",
        "\n",
        "  if not isinstance(percent, (int, float)):\n",
        "    raise ValueError(\"The percent value must be an INT or a FLOAT datatype\")\n",
        "  if not (0 < percent <= 1):\n",
        "    raise ValueError(\"The percent value for the sample size must fall within the interval (0, 1]\")\n",
        "\n",
        "  print(f\"{output_name} --> sampling {percent * 100:.3f}% of the dataset\")\n",
        "  df_sample = df.sample(False, float(percent), 42)\n",
        "\n",
        "  return df_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "od8fgj37yGaR"
      },
      "outputs": [],
      "source": [
        "stop_word=get_stop_words('en')\n",
        "split_regex = r'\\W+'\n",
        "\n",
        "def tokenize(string):\n",
        "  return [s for s in re.split(split_regex, string.lower()) if s != '' and not s in stop_word and not s.isdigit()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDMHnG7wkP83"
      },
      "source": [
        "## Downloading and sample size Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WceV-J7ayGj3",
        "outputId": "4b29aaf6-612a-4df6-e676-5f722fbc2db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to dataset\n",
            " 99% 1.05G/1.06G [00:16<00:00, 208MB/s]\n",
            "100% 1.06G/1.06G [00:16<00:00, 68.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the Kaggle datasets\n",
        "\n",
        "# Create folder for storing imported Kaggle dataset\n",
        "os.makedirs('dataset', exist_ok=True)\n",
        "\n",
        "# Authenticate Kaggle API\n",
        "kaggle_username = 'xxxxx' # Insert your Kaggle credentials\n",
        "kaggle_key = 'xxxxx'\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_username\n",
        "os.environ['KAGGLE_KEY'] = kaggle_key\n",
        "\n",
        "# Download the datasets and unzip\n",
        "!kaggle datasets download mohamedbakhet/amazon-books-reviews -p dataset --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnX93Jt0yGmP"
      },
      "outputs": [],
      "source": [
        "books_rating = spark.read.csv(\"dataset/Books_rating.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X76GmF7GyGod",
        "outputId": "61a6dd66-7435-41b8-a9a1-bcf68cf6f1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "books_rating --> sampling 10.000% of the dataset\n",
            "sample rating --> has 301036 row and 10 columns\n"
          ]
        }
      ],
      "source": [
        "# choose the % of dataset that you want to retrieve\n",
        "\n",
        "sample_rating = sample_size(books_rating,0.10,'books_rating')\n",
        "\n",
        "n_rows_sample_rating,n_cols_sample_rating=sample_rating.count(), len(sample_rating.columns)\n",
        "\n",
        "print(f'sample rating --> has {n_rows_sample_rating} row and {n_cols_sample_rating} columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u8a5NyvkfWb"
      },
      "source": [
        "## Data tansformation and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1LMp0zDyGqi"
      },
      "outputs": [],
      "source": [
        "# rename some columns for better reading\n",
        "\n",
        "sample_rating = sample_rating.select( col('Id').alias('Id'),\n",
        "                                      col('User_id').alias('User_id'),\n",
        "                                      #col('Title').alias('Title'),\n",
        "                                      #col('review/score').alias('score'),\n",
        "                                      #col('review/summary').alias('summary'),\n",
        "                                      col('review/text').alias('text')\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imXZXHKOyfA5"
      },
      "outputs": [],
      "source": [
        "# null values, beacause are noise for the tokenizer\n",
        "\n",
        "sample_rating=sample_rating.na.drop(subset=['text','User_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYWRpQpzyfDl"
      },
      "outputs": [],
      "source": [
        "rdd_sample_rating=sample_rating.rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVlFTRxFyfGX"
      },
      "outputs": [],
      "source": [
        "token_sample_rating=rdd_sample_rating.map(lambda s: ((s[0], s[1], s[2]), tokenize(s[2])))\n",
        "rating_flat = token_sample_rating.map(lambda x: (x[0][0], x[0][1],x[0][2], x[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA6ng4ryNzSx"
      },
      "outputs": [],
      "source": [
        "# filter the array token that are empty\n",
        "\n",
        "rating = rating_flat.toDF(\n",
        "    [\"Id\", \"User_id\",'text', \"tokens\"]\n",
        ")\n",
        "\n",
        "rating=rating.filter(size(col(\"tokens\")) > 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIrJoBwlkvNf"
      },
      "source": [
        "## Algorithm implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMn8xj5DlCF4"
      },
      "source": [
        "implementation through PySpark classes of hashing, MinHashing and computation of Jaccard distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G7s0BQK02l4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.ml.feature import HashingTF\n",
        "\n",
        "hashing_model = HashingTF(inputCol=\"tokens\", outputCol=\"features\", numFeatures= 8192)\n",
        "hashing_rating = hashing_model.transform(rating)\n",
        "\n",
        "\n",
        "from pyspark.ml.feature import MinHashLSH\n",
        "\n",
        "minhashing_model = MinHashLSH(inputCol=\"features\", outputCol=\"minhashes\", numHashTables=2)\n",
        "model = minhashing_model.fit(hashing_rating)\n",
        "\n",
        "s_th= 0.6\n",
        "\n",
        "similarity = model.approxSimilarityJoin(\n",
        "                                            hashing_rating,\n",
        "                                            hashing_rating,\n",
        "                                            threshold=s_th,\n",
        "                                            distCol=\"JaccardDistance\"\n",
        "                                          ).filter(\"datasetA.Id < datasetB.Id\")\n",
        "\n",
        "similarity = similarity.orderBy(\"JaccardDistance\", ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpD0TWpO1_RQ"
      },
      "outputs": [],
      "source": [
        "# a good evaluation of the model is to focus on these documents that are not identical\n",
        "\n",
        "similarity = similarity.filter(\n",
        "    (col(\"JaccardDistance\") > 0.1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjFdyExFlFt-"
      },
      "source": [
        "visualization of the algorithm results and their execution time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7h2VXfpjISTo"
      },
      "outputs": [],
      "source": [
        "\n",
        "similarity.select(\n",
        "    \"datasetA.Id\", \"datasetB.Id\", \"datasetA.text\", \"datasetB.text\", \"JaccardDistance\"\n",
        ").limit(10).collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrg8H8imISWV"
      },
      "outputs": [],
      "source": [
        "first_pair = similarity.first()\n",
        "\n",
        "review_a = first_pair['datasetA']['text']\n",
        "review_b = first_pair['datasetB']['text']\n",
        "\n",
        "# Printing the reviews\n",
        "print(\"Review 1 (datasetA):\")\n",
        "print(review_a)\n",
        "print(\"\\nReview 2 (datasetB):\")\n",
        "print(review_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocFV7xgrISY1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m3TyG_8ISbS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg7B2FwCmzxkHFfWBDZfEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}